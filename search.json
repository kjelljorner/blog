[
  {
    "objectID": "posts/2022-09-02-prediction-intervals/index.html",
    "href": "posts/2022-09-02-prediction-intervals/index.html",
    "title": "Prediction intervals for any machine learning model",
    "section": "",
    "text": "The generalization error of a machine learning model is often given as the mean absolute error (MAE) or the root mean squared error (RMSE). Sometimes, the goodness of fit is given as the coefficient of determination, R2. While these metrics give an impression of the accuracy of the model on average, they do not really give a good representation of the error that can be expected for a single new prediction. Ironically, that is probably the quantity that the end user of the model is most interested in.\nTechnically speaking, the MAE gives the average error of the model for new data points drawn from the same “distribution” as the training set. That would correspond to the average error for many predictions, while each individual prediction can have much larger error. The prediction interval is used to quantify the uncertainty of an individual prediction. For some models, such as (multivariate) linear regression, there is an analytic expression for the prediction interval. For Bayesian methods, such as Gaussian Process Regression, the prediction intervals are readily obtained together with the model predictions. For other types of machine learning models, it’s not immediately obvious how to obtain prediction intervals as analytic expressions are not available.\nOne approach is conformal prediction, implemented in for example the nonconformist Python package. We will not investigate conformal prediction further in this blog post, but instead focus on a method called the Jackknife+1. It is similar to conformal prediction, and an up-to-date Python implementation is available in the MAPIE package. I actually wrote my own implementation of the Jackknife+ as part of my modelling of the SNAr reaction2, and was now thinking of packaging it up when I discovered that the people behind MAPIE had already done a much better job than I could expect to do.\nIn this blog post, we will test out MAPIE and compare its prediction intervals to those from normal linear regression as well as Bayesian linear regression."
  },
  {
    "objectID": "posts/2022-08-13-interactive/index.html",
    "href": "posts/2022-08-13-interactive/index.html",
    "title": "Interactive molecular content",
    "section": "",
    "text": "I recently rebased the blog on the Quarto publishing system. Quarto is an evolution of R Markdown and allows publishing a notebook (.qmd or .ipynb) in various formats, inlcuding as blog posts.\nIn the previous post on visualizing atomic type orbitals, we had some code for interactive visualization with ipywidgets. Unfortunately, it didn’t work in the browser as it needs a Python backend running. With Quarto as publishing system, we can work around that problem.\nThanks to the support for the Observable dialect of JavaScript (OJS) in Quarto, we can create interactive elements which will work on the final static webpage. This will require some level of proficiency with JavaScript, but rest assured that I knew zero JavaScript when I started writing this blog post. The code cells featuring OJS are hidden in this post, but can be shown by clicking on the arrow next to “Code”. But first we will start with a visualization that doesn’t need any JavaScript skills."
  },
  {
    "objectID": "posts/2022-08-13-interactive/index.html#visualing-molecules-with-molplotly",
    "href": "posts/2022-08-13-interactive/index.html#visualing-molecules-with-molplotly",
    "title": "Interactive molecular content",
    "section": "Visualing molecules with molplotly",
    "text": "Visualing molecules with molplotly\nmolplotly is a great add-on to plotly to display data together with 2D images of the associated molecules. It is really easy to use and works nicely in a Jupyter Notebook, but requires a Dash app to run in the background. Here we will instead use Bokeh to create similar plots which can be displayed on a static webpage, although with a bit more effort. See the Bokeh documentation as well as the blog post by iwatobipen and the notebook from OpenEye Software for more ideas.\nWe visualize the ESOL dataset,1 downloaded from MoleculeNet.\n\nfrom bokeh.io import output_notebook\nfrom bokeh.models import HoverTool\nfrom bokeh.plotting import figure, show, ColumnDataSource\nimport pandas as pd\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\n\n# Read the csv file\ndf = pd.read_csv(\"delaney-processed.csv\")\n\n# Get data to plot\nall_smiles = df[\"smiles\"]\nx = df[\"measured log solubility in mols per litre\"].values\ny = df[\"Molecular Weight\"].values\n\n# Create SVGs for each smiles with the \"new\" RDKit drawing code\nimgs = []\nfor smiles in all_smiles:\n    mol = Chem.MolFromSmiles(smiles)\n    d2d = Chem.Draw.MolDraw2DSVG(150, 150)\n    d2d.DrawMolecule(mol)\n    d2d.FinishDrawing()\n    svg = d2d.GetDrawingText()\n    imgs.append(svg)\n\n# Configure for output in the notebook\noutput_notebook()\n\n# Load the data into a source and plot\nsource = ColumnDataSource(\n    data={\n        \"x\": x,\n        \"y\": y,\n        \"imgs\": imgs,\n        \"smiles\": all_smiles,\n    }\n)\np = figure()\np.scatter(\"x\", \"y\", source=source)\np.plot_height = 300\np.plot_width = 400\np.sizing_mode = \"scale_width\"\np.xaxis.axis_label = \"Molecular weight\"\np.yaxis.axis_label = \"log S\"\n\n# Create tooltips referencing stored images\nTOOLTIPS = \"\"\"\\\n    <div>\n        <div>\n            @imgs{safe}\n        </div>\n        <div>\n            <span>[$index]</span>\n        </div>\n        <div>\n            <span>@smiles{safe}</span>\n        </div>\n        <div>\n            <span>($x, $y)</span>\n        </div>\n    </div>\n\"\"\"\n\n# Connect tooltips to plot\np.add_tools(HoverTool(tooltips=TOOLTIPS))\n\n# Show figure\nshow(p)\n\n\n        \n        Loading BokehJS ..."
  },
  {
    "objectID": "posts/2022-08-13-interactive/index.html#visualizing-different-conformers",
    "href": "posts/2022-08-13-interactive/index.html#visualizing-different-conformers",
    "title": "Interactive molecular content",
    "section": "Visualizing different conformers",
    "text": "Visualizing different conformers\nAs a second exercise, we are going to create a number of conformers for the propanal molecule using morfeus. We save one file with lowest energy conformer and one file with all the conformers. The function ojs_define is special to Quarto and allows passing data from Python or R to OJS. We use it to send over a list of the conformer energies for later display.\n\nfrom morfeus.conformer import ConformerEnsemble, _extract_from_mol\nfrom morfeus.io import write_xyz\n\n# Optimize propanal conformers\nsmiles = \"CCC=O\"\nce = ConformerEnsemble.from_rdkit(smiles, optimize=\"MMFF94\", random_seed=42)\nce.prune_rmsd()\nce.sort()\n\n# Write out conformers\nce.write_xyz(\"lowest.xyz\", ids=[0])\nce.align_conformers()\nelements, conformer_coordinates, _, _ = _extract_from_mol(ce.mol)\nwrite_xyz(\"conformers.xyz\", elements, conformer_coordinates)\n\n# Send variables to OJS\nojs_define(confEnergies=list(ce.get_relative_energies()))\n\n\nNow we will create the interactive visualization with 3Dmol.js.2 We will first create an input slider to allow the reader to select which conformer to show. This is done with Inputs.range in OJS (click “Code” to reveal the OJS code). We then use 3DMol.js to load the conformers.xyz file and define the function updateViewer which we couple to the input slider. There is a Python interface to 3Dmol called py3Dmol, but it currently cannot generate the level of interactivity that we need.\nWe create a slider to choose the conformer, and a reactive label that prints the energy of the currently selected conformer.\n\n\nCode\nviewof confIDInput = Inputs.range([1, confEnergies.length], {value: 1, step: 1, label: \"Conformer ID\"});\nmd`Energy (kcal/mol): ${confEnergies[confIDInput - 1].toFixed(3)}`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n// Create container\ndivConf = html`<div style=\"width:${layoutWidth[\"layout-conf\"]}px;height:${layoutWidth[\"layout-conf\"] * 2 / 3}px;position:relative\"></div>`;\n\n\n\n\n\n\n\n\n\n\nCode\njquery = require(\"jquery\");\n$3Dmol = require(\"3dmol\");\nNGL = require(\"ngl@next\");\n\n// Create viewer\nviewerConf = {\n  let xyzString = await FileAttachment(\"conformers.xyz\").text();\n  let viewer = $3Dmol.createViewer(divConf, {});\n  viewer.addModelsAsFrames(xyzString, \"xyz\");\n  viewer.setStyle({stick:{}});\n  viewer.zoomTo();\n  viewer.render();\n  return viewer;\n};\n\nupdateViewer = function(viewer, ID){\n  viewer.setFrame(ID);\n  viewer.render();\n  return viewer;\n};\n\nupdateViewer(viewerConf, confIDInput - 1);"
  },
  {
    "objectID": "posts/2022-08-13-interactive/index.html#optimization-trajectory",
    "href": "posts/2022-08-13-interactive/index.html#optimization-trajectory",
    "title": "Interactive molecular content",
    "section": "Optimization trajectory",
    "text": "Optimization trajectory\nNext we will display the results of a geometry optimization. To do the optimization we are going to use the PyBerny package, which is a partial Python re-implementation of the algorithm described by Bernhard Schlegel and co-workers.3.\nWe then use PyBerny together with the MOPAC backend to optimize the molecule. MOPAC is nowadays available for free and can be installed with conda.\n$ conda install -c conda-forge mopac\nWe store all the energies and coordinates and write an xyz file with the whole optimization trajectory. wurlitzer is needed to suppress some output from MOPAC.\n\nfrom berny import Berny, geomlib\nfrom berny.solvers import MopacSolver\nfrom wurlitzer import pipes\nfrom morfeus.io import write_xyz\nfrom morfeus.data import HARTREE_TO_KCAL, HARTREE_TO_EV\n\noptimizer = Berny(geomlib.readfile(\"lowest.xyz\"))\nsolver = MopacSolver()\nnext(solver)\ntraj = []\nenergies = []\nwith pipes() as (stdout, stderr):\n    for geom in optimizer:\n        energy, gradients = solver.send((list(geom), geom.lattice))\n        optimizer.send((energy, gradients))\n        traj.append(geom)\n        energies.append(energy)\nenergies = [\n    (energy - energies[-1]) * HARTREE_TO_KCAL + 1e-8 for energy in energies\n]  # add small energy to avoid bug in observable plot\nwrite_xyz(\"traj.xyz\", traj[0].species, [geom.coords for geom in traj])\n\nNow we want to calculate some additional information to use in the visualization. That includes the bond lenghts of the C1–C2 bond for each step of the trajectory, which we store in labels. We also pass over the data on the energies for each step as a Pandas DataFrame.\n\nfrom morfeus.io import read_xyz\nimport scipy.spatial\nimport pandas as pd\n\n# Calculate the bond distance labels\n_, coordinates = read_xyz(\"traj.xyz\")\nlabels = [scipy.spatial.distance_matrix(coord, coord)[0, 1] for coord in coordinates]\n\n# Pass the variables onto Observable\nopt_data = pd.DataFrame({\"step\": range(1, len(energies) + 1), \"energy\": energies})\nojs_define(labels=labels, optData=opt_data)\n\n\nTo be able to animate the trajectory we need to use a special type of input object that is not part of the standard Observable inputs. Luckily, the Observable creator Mike Bostock has created the Scrubber for us to do this work and we can easily import it.\n\n\nCode\nimport {Scrubber} from \"@mbostock/scrubber\"\nnumbers = Array.from({length: labels.length}, (_, i) => i + 1);\nviewof frameIDInput = Scrubber(numbers, {delay: 500, autoplay: false})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n// Create drawing area\ndivBerny = html`<div style=\"width:${layoutWidth[\"layout-berny\"] / 2}px;height:${layoutWidth[\"layout-berny\"] / 3}px;position=\"relative\"></div>`;\n\n\n\n\n\n\n\n\n\nCode\nplot = Plot.plot({\n  x: {label: \"→ Step\"},\n  y: {label: \"↑ Energy (kcal/mol)\"},\n  style: {fontSize: 20},\n  margin: 50,\n  marks: [\n    Plot.line(transpose(optData), \n      { x: \"step\", y: \"energy\"}, \n      { stroke: \"black\" }\n    ),\n    Plot.dot(transpose(optData), Plot.select(I => [frameIDInput - 1], {x: \"step\", y: \"energy\"})),\n    Plot.text(transpose(optData), Plot.select(I => [frameIDInput - 1], {x: \"step\", y: \"energy\", text: \"energy\", dx: 10, dy: -10}))\n  ]}\n);\n\n\n\n\n\n\n\n\n\n\n\nCode\nviewerBerny = {\n  let xyzString = await FileAttachment(\"traj.xyz\").text();\n  let viewer = $3Dmol.createViewer(divBerny);\n  viewer.addModelsAsFrames(xyzString, \"xyz\");\n  viewer.setStyle({stick: {}});\n  for (let i = 0; i < viewer.getNumFrames(); i++) {\n      viewer.addLabel(labels[i].toFixed(3), {alignment: \"center\", frame: i}, {serial: [1, 2]});\n  };  \n  viewer.zoomTo();\n  viewer.render();\n  return viewer;\n};\n\n// Update the view\nupdateViewer(viewerBerny, frameIDInput - 1)"
  },
  {
    "objectID": "posts/2022-08-13-interactive/index.html#molecular-orbitals",
    "href": "posts/2022-08-13-interactive/index.html#molecular-orbitals",
    "title": "Interactive molecular content",
    "section": "Molecular orbitals",
    "text": "Molecular orbitals\nWe’re now ready to tackle the interactive visualization of molecular orbitals. We again use PySCF to generate them. We send over the orbital occupations numbers and energies for display with OJS.\n\nimport pyscf\nfrom pyscf import gto, lo, tools, dft\n\nelements, coordinates = read_xyz(\"lowest.xyz\")\natoms = [(element, coordinate) for element, coordinate in zip(elements, coordinates)]\npyscf_mole = gto.Mole(basis=\"sto-3g\")\npyscf_mole.atom = atoms\npyscf_mole.build()\n\nmf = dft.RKS(pyscf_mole)\nmf.xc = \"b3lyp\"\nmf.run()\n\nn_orbs = mf.mo_coeff.shape[1]\nfor i in range(n_orbs):\n    tools.cubegen.orbital(\n        pyscf_mole, f\"mo_{i+1:02d}.cube\", mf.mo_coeff[:, i], nx=40, ny=40, nz=40\n    )\n\nhomo_ID = pyscf_mole.nelectron // 2\nmo_energies = list(mf.mo_energy * HARTREE_TO_EV)\nmo_data = pd.DataFrame({\"energy\": mo_energies})\nojs_define(\n    MOOccs=list(mf.mo_occ), MOEnergies=mo_energies, homoID=homo_ID, MOData=mo_data\n)\n\n\nWe now create a slider to select the MO number, as well as an input box to select the isodensity surface value. We show both the orbitals, and a “tick” plot made with Observable Plot to show were the selected orbital lies in the manifold.\n\n\nCode\nviewof MOIDInput = Inputs.range([1, MOOccs.length], {value: homoID, step: 1, label: \"MO ID\"});\nviewof MOIsoInput = Inputs.number([0.0, Infinity], {value: 0.04, step: 0.0001, label: \"Isodensity value\"});\nmd`Occ: ${MOOccs[MOIDInput - 1]}  \nEnergy (eV): ${MOEnergies[MOIDInput - 1].toFixed(3)}`;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n// Create drawing area\ndivMO = html`<div style=\"width:${layoutWidth[\"layout-mo\"] / 2}px;height:${layoutWidth[\"layout-mo\"] / 3}px;position=\"relative\"></div>`;\n\n\n\n\n\n\n\n\n\nCode\nplot_mo = Plot.plot({\n  y: {\n    domain: [-30, d3.max(MOData[\"energy\"])],\n    label: \"↑ Energy (eV)\"\n  },\n  style: {fontSize: 20},  \n  margin: 40,\n  marks: [\n    Plot.tickY(transpose(MOData), {y: \"energy\"}),\n    Plot.tickY(transpose(MOData), Plot.select(I => [MOIDInput - 1], {y: \"energy\", strokeWidth: 3}))\n  ]}\n);\n\n\n\n\n\n\n\n\n\n\n\nCode\nMOStrings = [ \n    await FileAttachment(\"mo_01.cube\").text(),\n    await FileAttachment(\"mo_02.cube\").text(),\n    await FileAttachment(\"mo_03.cube\").text(),\n    await FileAttachment(\"mo_04.cube\").text(),\n    await FileAttachment(\"mo_05.cube\").text(),\n    await FileAttachment(\"mo_06.cube\").text(),\n    await FileAttachment(\"mo_07.cube\").text(),\n    await FileAttachment(\"mo_08.cube\").text(),\n    await FileAttachment(\"mo_09.cube\").text(),\n    await FileAttachment(\"mo_10.cube\").text(),\n    await FileAttachment(\"mo_11.cube\").text(),\n    await FileAttachment(\"mo_12.cube\").text(),\n    await FileAttachment(\"mo_13.cube\").text(),\n    await FileAttachment(\"mo_14.cube\").text(),\n    await FileAttachment(\"mo_15.cube\").text(),\n    await FileAttachment(\"mo_16.cube\").text(),\n    await FileAttachment(\"mo_17.cube\").text(),\n    await FileAttachment(\"mo_18.cube\").text(),\n    await FileAttachment(\"mo_19.cube\").text(),\n    await FileAttachment(\"mo_20.cube\").text(),\n    await FileAttachment(\"mo_21.cube\").text(),\n    await FileAttachment(\"mo_22.cube\").text(),\n    await FileAttachment(\"mo_23.cube\").text(),\n    await FileAttachment(\"mo_24.cube\").text(),\n    await FileAttachment(\"mo_25.cube\").text(),\n    await FileAttachment(\"mo_26.cube\").text()\n]\n\n// Create viewer\nviewerMO = {\n  let xyzString = await FileAttachment(\"lowest.xyz\").text();\n  let viewer = $3Dmol.createViewer(divMO, {});\n  viewer.addModelsAsFrames(xyzString.repeat(MOOccs.length), \"xyz\");\n  viewer.setStyle({stick: {}});\n  for (let i = 0; i < MOOccs.length; i++) {\n    viewer.addVolumetricData(MOStrings[i], \"cube\", {\"isoval\": -MOIsoInput, \"color\": \"red\", \"opacity\": 0.8, frame: i});\n    viewer.addVolumetricData(MOStrings[i], \"cube\", {\"isoval\": MOIsoInput, \"color\": \"blue\", \"opacity\": 0.8, frame: i});\n    viewer.render();    \n  };    \n  viewer.zoomTo();\n  viewer.render();\n  return viewer;\n};\n\nupdateViewer(viewerMO, MOIDInput - 1);"
  },
  {
    "objectID": "posts/2022-08-13-interactive/index.html#surface-properties",
    "href": "posts/2022-08-13-interactive/index.html#surface-properties",
    "title": "Interactive molecular content",
    "section": "Surface properties",
    "text": "Surface properties\n3Dmol can also be used to display surfaces. Here we generate the total electron density and the electrostatic potential as cube files.\n\ndm = mf.make_rdm1()\ntools.cubegen.density(pyscf_mole, \"density.cube\", dm,  nx=40, ny=40, nz=40)\ntools.cubegen.mep(pyscf_mole, \"esp.cube\", dm,  nx=40, ny=40, nz=40)\n\nWe then create a visualization of the surface and an input box to select the isodensity value.\n\n\nCode\n// Create input slider\nviewof isoInput = Inputs.number([0.0, Infinity], {value: 0.001, step: 0.0001, label: \"Isodensity value\"});\n\n\n\n\n\n\n\n\n\n\nCode\n// Create drawing area\ndivDensity = html`<div style=\"width:${layoutWidth[\"layout-density\"]}px;height:${layoutWidth[\"layout-density\"] * 2 / 3}px;position:relative\"></div>`;\n\n\n\n\n\n\n\n\n\n\nCode\nviewerDensity = {\n  let xyz_string = await FileAttachment(\"lowest.xyz\").text();\n  let viewer = $3Dmol.createViewer(divDensity, {});\n  viewer.addModel(xyz_string, \"xyz\");\n  viewer.setStyle({stick: {}});\n  viewer.zoomTo();\n  viewer.render();\n  return viewer;\n};\n\nadd_iso = function(viewer, voldata, isoValue) {\n  viewer.removeAllShapes();\n  viewer.addIsosurface(voldata, {isoval: isoValue, color: \"lightgray\", opacity:0.85});\n  viewer.render();\n};\n\n{\n  let densityString = await FileAttachment(\"density.cube\").text();\n  let voldata = new $3Dmol.VolumeData(densityString, \"cube\");\n  add_iso(viewerDensity, voldata, isoInput);\n};\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can do the same thing with an electrostatic potential (ESP) surface, where we map the ESP onto an isodensity surface.\n\n\nCode\n// Create input object\nviewof ESPInput = Inputs.number([0.0, Infinity], {value: 0.001, step: 0.0001, label: \"Isodensity value\"});\n\n\n\n\n\n\n\n\n\n\nCode\ndiv_ESP = html`<div style=\"width:${layoutWidth[\"layout-esp\"]}px;height:${layoutWidth[\"layout-esp\"] * 2 / 3}px;position:relative\"></div>`;\n\n// Create a color legend\nPlot.legend({label: \"esp\", color: {scheme: \"rdbu\", domain: [-1, 1]}, width: layoutWidth[\"layout-esp\"] / 3})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nviewerESP = {\n  let xyzString = await FileAttachment(\"lowest.xyz\").text();\n  let viewer = $3Dmol.createViewer(div_ESP, {});\n  viewer.addModelsAsFrames(xyzString, \"xyz\");\n  viewer.setStyle({stick: {}});\n  viewer.zoomTo();\n  viewer.render();\n  return viewer;\n};\n\n// Create function to add ESP to viewer\nadd_esp = function(viewer, densityString, espString, isoValue) {\n  viewer.removeAllShapes();\n  viewer.addVolumetricData(densityString, \"cube\", {\"isoval\": isoValue, \"smoothness\": 2, \"opacity\": 0.95, \"voldata\": espString, \"volformat\": \"cube\", \"volscheme\": {\"gradient\":\"rwb\", \"min\":-.1, \"max\":.1}});\n  viewer.render();\n};\n\n// Draw the ESP\n{\n  let densityString = await FileAttachment(\"density.cube\").text();\n  let espString = await FileAttachment(\"esp.cube\").text();\n  add_esp(viewerESP, densityString, espString, ESPInput);\n}"
  },
  {
    "objectID": "posts/2022-08-13-interactive/index.html#ngl",
    "href": "posts/2022-08-13-interactive/index.html#ngl",
    "title": "Interactive molecular content",
    "section": "NGL",
    "text": "NGL\nAn alternative to 3Dmol is NGL.4 There is a very nice IPython/Jupyter widget called nglview that is based on NGL. Unfortunately, I also couldn’t get functionalities like the Trajectory to work interactively. Therefore we work around this and use the NGL library directly with JavaScript and make our own interactive controls as we did above for 3Dmol.\nFirst we need to create a structure file that can be read by NGL. The PDB format is most convenient for this purpose and we use Atomic Simulation Environment to help us rewrite the multi-structure xyz file to a multi-structure pdb file.\n\nimport ase.io\n\ntraj = [atoms for atoms in ase.io.iread(\"conformers.xyz\")]\nase.io.write(\"confomers.pdb\", traj)\n\nWe are now ready to visualize the PDB file with NGL.\n\n\nCode\nviewof trajInput = Inputs.range([1, confEnergies.length], {value: 1, step: 1, label: \"Conformer ID\"});\nmd`Energy (kcal/mol): ${confEnergies[trajInput - 1].toFixed(3)}`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n// Create drawing area\ndivNGL = html`<div style=\"width:${layoutWidth[\"layout-ngl\"]}px;height:${layoutWidth[\"layout-ngl\"] * 2 / 3}px;position:relative\"></div>`;\n\n\n\n\n\n\n\n\n\n\nCode\ntrajPDB = {\n  let stage = new NGL.Stage(divNGL, {clipDist: 0.0, backgroundColor: \"white\"});\n  let pdbString = await FileAttachment(\"confomers.pdb\").blob();\n  let structure = await stage.loadFile(pdbString, {ext: \"pdb\", asTrajectory: true})\n  let traj = structure.addTrajectory().trajectory\n  structure.addRepresentation(\"licorice\");\n  structure.autoView();\n  return traj;\n};\n\n// Create function to update trajectory\nupdate_traj = function(traj, id){\n  traj.setFrame(id)\n};\n\n// Update trajectory based on slider\nupdate_traj(trajPDB, trajInput - 1);"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Kjell Jorner",
    "section": "",
    "text": "From January 2023, I will be an Assistant Professor of Digital Chemistry at ETH Zurich.\nAll views my own."
  },
  {
    "objectID": "posts/2022-09-02-prediction-intervals/index.html#analytic-prediction-intervals-from-linear-regression",
    "href": "posts/2022-09-02-prediction-intervals/index.html#analytic-prediction-intervals-from-linear-regression",
    "title": "Prediction intervals for any machine learning model",
    "section": "Analytic prediction intervals from linear regression",
    "text": "Analytic prediction intervals from linear regression\nThe first model to use when trying to understand a statistical concept is usually linear regression. We can always complicate things with non-linear models, but the concepts themselves can be intuitively understood better with a simpler model.\nFirst we just do a quick cross-validation on the entire dataset to see that the model is reasonable.\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import make_scorer, mean_absolute_error\nimport scipy.stats\n\nest = LinearRegression()\nscores = cross_val_score(est, X, y, cv=10, scoring=make_scorer(mean_absolute_error))\nsem = scipy.stats.sem(scores)\nprint(f\"Mean absolute error with 95% CI: {np.mean(scores):.3f} ± {sem * 1.96:.3f}\")\n\nMean absolute error with 95% CI: 0.187 ± 0.010\n\n\nTo put this error into context, it’s a bit worse than what Denmark (MAE: 0.152) or Glorius (MAE: 0.144) got with their methods, although a more rigorous comparison would need to be done. We are anyway trying to keep things simple here.\nNow we want to get the prediction intervals. As mentioned above, they are readily available with linear regression. However, due to the aforementioned non-interest in prediction intervals from most machine learning practitioners, we cannot get them from scikit-learn but have to compute them ourselves. Here we use the recipe from the blog post on Machine Learning Mastery.\n\nimport matplotlib.pyplot as plt\nfrom mapie.metrics import regression_coverage_score\n\n# Fit the scikit-learn model\nest = LinearRegression()\nest.fit(X_train, y_train)\ny_train_pred = est.predict(X_train)\ny_test_pred = est.predict(X_test)\n\n# Compute prediction intervals\nsum_of_squares = np.sum((y_train - y_train_pred) ** 2)\nstd = np.sqrt(1 / (len(y_train) - 2) * sum_of_squares)\n\n# Plot the prediction intervals\ny_err = np.vstack([std, std]) * 1.96\nplt.errorbar(y_test, y_test_pred, yerr=y_err, fmt=\"o\", ecolor=\"gray\", capsize=3)\nplt.plot(plt.xlim(), plt.xlim(), color=\"lightgray\", scalex=False, scaley=False)\nplt.xlabel(\"Experiment\")\nplt.ylabel(\"Predicted\")\n\n# Print out statistics\nmae_test = mean_absolute_error(y_test, y_test_pred)\nprint(f\"MAE: {mae_test:.3f}\")\nprint(f\"Width of 95% prediction interval: {np.mean(y_err) * 2:3f}\")\ncoverage = regression_coverage_score(\n    y_test, y_test_pred - std * 1.96, y_test_pred + std * 1.96\n)\nprint(f\"Coverage: {coverage:.3f}\")\n\nMAE: 0.204\nWidth of 95% prediction interval: 0.904925\nCoverage: 0.888\n\n\n\n\n\nWe have plotted the true values on the x-axis and the predictions on the y-axis. We have specified a prediction interval at 95%, so we expect the error bars to cover the identity line \\(y=x\\) in 95% of the cases (a coverage of 0.95).\nA prediction interval of ca 0.9 kcal/mol gives completely different sense of how accurate the prediction for a new compound is likely to be. The end user of the model can then decide whether they are comfortable with the uncertainty of the prediction. The right level of confidence could of course be adjusted depending on the application – 95% is not god-given. We also see that the coverage is a bit lower at 0.89 than what we requested, 0.95."
  },
  {
    "objectID": "posts/2022-09-02-prediction-intervals/index.html#prediction-intervals-from-bayesian-ridge-regression",
    "href": "posts/2022-09-02-prediction-intervals/index.html#prediction-intervals-from-bayesian-ridge-regression",
    "title": "Prediction intervals for any machine learning model",
    "section": "Prediction intervals from Bayesian Ridge Regression",
    "text": "Prediction intervals from Bayesian Ridge Regression\nOne of my favorite machine learning models is Bayesian ridge regression, a Bayesian version of the tried-and-true ridge regression. It is perfect as a black-box linear baseline model that automatically does regularization and gives prediction intervals.\n\nfrom sklearn.linear_model import BayesianRidge\n\n# Fit model\nest = BayesianRidge()\nest.fit(X_train, y_train)\ny_test_pred, y_test_std = est.predict(X_test, return_std=True)\n\n# Plot the data with the error bars\ny_err = np.vstack([y_test_std, y_test_std]) * 1.96 / 2\nplt.errorbar(y_test, y_test_pred, yerr=y_err, fmt=\"o\", ecolor=\"gray\", capsize=3)\nplt.plot(plt.xlim(), plt.xlim(), color=\"lightgray\", scalex=False, scaley=False)\n\n# Print out statistics\nmae_test = mean_absolute_error(y_test, y_test_pred)\nprint(f\"MAE: {mae_test:.3f}\")\nprint(f\"Width of 95% prediction interval: {np.mean(y_err) * 2:3f}\")\ncoverage = regression_coverage_score(\n    y_test, -y_err[0] + y_test_pred, y_err[1] + y_test_pred\n)\nprint(f\"Coverage: {coverage:.3f}\")\n\nMAE: 0.202\nWidth of 95% prediction interval: 1.266978\nCoverage: 0.937\n\n\n\n\n\nThe Bayesian model has a very similar MAE as the regular linear regression, but the prediction intervals are wider at 1.3 kcal/mol and the coverage is therefore also better at 0.94."
  },
  {
    "objectID": "posts/2022-09-02-prediction-intervals/index.html#dataset",
    "href": "posts/2022-09-02-prediction-intervals/index.html#dataset",
    "title": "Prediction intervals for any machine learning model",
    "section": "Dataset",
    "text": "Dataset\nWe will use a dataset from the Denmark group used to construct machine learning models for prediction of enantioselectivity3. The dataset that we use is actually taken from another paper, by the Glorius group4. The reaction is shown in Figure 1 together with the original results of the Denmark group as well as those from the MFF approach by the Glorius group.\n\n\n\nFigure 1: N,S-acetal formation using chiral phosphoric aid (CPA) catalysts by Denmark and co-workers.\n\n\nFirst we load the dataset and generate features for the reactions. In this case, we keep things simple and just generate Morgan/ECFP fingerprints with a radius of 3 and a size of 512, for computational efficiency. Actually, I learned about GetMorganGenerator when writing this post. It makes it very easy to get the fingerprints as NumPy arrays using the GetFingerprintAsNumPy method.\nWe’ll do a simple train-test split, where we use the train set to derive the prediction intervals, and the test set to check how good they are.\n\nimport pandas as pd\nimport numpy as np\nfrom rdkit import Chem\nfrom rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator\nfrom sklearn.model_selection import train_test_split\n\n# Load dataset\ndf = pd.read_excel(\"denmark.xlsx\")\ny = df[\"Output\"].values\n\n# Generate fingerprints\ngen = GetMorganGenerator(radius=3, fpSize=512)\nfp_catalyst = df[\"Catalyst\"].apply(\n    lambda x: gen.GetFingerprintAsNumPy(Chem.MolFromSmiles(x))\n)\nfp_imine = df[\"Imine\"].apply(lambda x: gen.GetFingerprintAsNumPy(Chem.MolFromSmiles(x)))\nfp_thiol = df[\"Thiol\"].apply(lambda x: gen.GetFingerprintAsNumPy(Chem.MolFromSmiles(x)))\n\nX = np.hstack(\n    [np.vstack(i) for i in [fp_catalyst.values, fp_imine.values, fp_thiol.values]]\n)\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
  },
  {
    "objectID": "posts/2022-09-02-prediction-intervals/index.html#prediction-intervals-with-mapie",
    "href": "posts/2022-09-02-prediction-intervals/index.html#prediction-intervals-with-mapie",
    "title": "Prediction intervals for any machine learning model",
    "section": "Prediction intervals with MAPIE",
    "text": "Prediction intervals with MAPIE\nNow for the most exciting part, we can use MAPIE to calculate the prediction intervals.\n\nfrom mapie.regression import MapieRegressor\n\n# Train model\nest = LinearRegression()\nmapie = MapieRegressor(est, cv=10, agg_function=\"median\")\nmapie.fit(X_train, y_train)\ny_test_pred, y_test_pis = mapie.predict(X_test, alpha=[0.05])\n\n# Plot the data with the error bars\ny_err = np.abs(y_test_pis[:, :, 0].T - y_test_pred)\nplt.errorbar(y_test, y_test_pred, yerr=y_err, fmt=\"o\", ecolor=\"gray\", capsize=3)\nplt.plot(plt.xlim(), plt.xlim(), color=\"lightgray\", scalex=False, scaley=False)\n\n# Print out statistics\nmae_test = mean_absolute_error(y_test, y_test_pred)\nprint(f\"MAE: {mae_test:.3f}\")\nprint(f\"Width of 95% prediction interval: {np.mean(y_err) * 2:3f}\")\ncoverage = regression_coverage_score(y_test, y_test_pis[:, 0, 0], y_test_pis[:, 1, 0])\nprint(f\"Coverage: {coverage:.3f}\")\n\nMAE: 0.204\nWidth of 95% prediction interval: 1.083446\nCoverage: 0.918\n\n\n\n\n\nThe MAE of the linear regression model is exactly the same as before - we are only changing the way that we calculate the prediction intervals. Here, the prediction interval width at 1.1 kcal/mol and the coverage of 0.92 is in between the regular linear regression and the Bayesian ridge version.\n\n\n\n\n\n\nNote\n\n\n\nThe default for the keyword agg_function for MapieRegressor is “mean”. This is not completely rigorous, so we changed it here to “median” as used in the original article on the Jackknife+.1 In practice, it probably doesn’t matter to much which one you chose.5\n\n\nNow for the interesting part – let’s try a method where we don’t normally get prediction intervals easily.\n\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Train model\nest = RandomForestRegressor(n_estimators=10, random_state=42)\nmapie = MapieRegressor(est, cv=10, agg_function=\"median\")\nmapie.fit(X_train, y_train)\ny_test_pred, y_test_pis = mapie.predict(X_test, alpha=[0.05])\n\n# Plot the data with the error bars\ny_err = np.abs(y_test_pis[:, :, 0].T - y_test_pred)\nplt.errorbar(y_test, y_test_pred, yerr=y_err, fmt=\"o\", ecolor=\"gray\", capsize=3)\nplt.plot(plt.xlim(), plt.xlim(), color=\"lightgray\", scalex=False, scaley=False)\n\n# Print out statistics\nmae_test = mean_absolute_error(y_test, y_test_pred)\nprint(f\"MAE: {mae_test:.3f}\")\nprint(f\"Width of 95% prediction interval: {np.mean(y_err) * 2:3f}\")\ncoverage = regression_coverage_score(y_test, y_test_pis[:, 0, 0], y_test_pis[:, 1, 0])\nprint(f\"Coverage: {coverage:.3f}\")\n\nMAE: 0.165\nWidth of 95% prediction interval: 0.942551\nCoverage: 0.937\n\n\n\n\n\nAnd voilà, we have the prediction intervals for a random forest model without much effort.\n\n\n\n\n\n\nTip\n\n\n\nThere are other approaches to getting prediction intervals for random forest, such as quantile regression or Natural Gradient Boosting. There are even more efficient ways of using ensemble models such as Random Forest together with Jackknife+ using the Jackknife+ after Bootstrap approach.5"
  },
  {
    "objectID": "posts/2022-09-02-prediction-intervals/index.html#conclusions",
    "href": "posts/2022-09-02-prediction-intervals/index.html#conclusions",
    "title": "Prediction intervals for any machine learning model",
    "section": "Conclusions",
    "text": "Conclusions\nPrediction intervals are one of the most important pieces of information for an end user of a machine learning model. Unfortunately, they are mostly neglected in practice, with focus instead being placed on the average error of new predictions. Here we went through three examples of easily getting prediction intervals in Python, with application to a reaction prediction problem:\n\nMethods with analytical expressions, with linear regression as an example\nBayesian methods, with Bayesian ridge regression as an example\nModel-agnostic methods, with the Jackknife+ as an example"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Valence Kjell",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nPrediction intervals for any machine learning model\n\n\nHow to construct prediction intervals with the Jackknife+ using the MAPIE package\n\n\n\n\n\n\nSep 14, 2022\n\n\nKjell Jorner\n\n\n\n\n\n\n  \n\n\n\n\nInteractive molecular content\n\n\nHow to embed interactive content in webpages with Quarto using Bokeh, 3DMol.js and NGL\n\n\n\n\n\n\nAug 13, 2022\n\n\nKjell Jorner\n\n\n\n\n\n\n  \n\n\n\n\nFrontier molecular orbitalets\n\n\nHow to compute and visualize orbitalets with PySCF\n\n\n\n\n\n\nJul 17, 2022\n\n\nKjell Jorner\n\n\n\n\n\n\n  \n\n\n\n\nVisualizing atomic type orbitals in molecules\n\n\nHow to compute and visualize natural atomic orbitals with PySCF\n\n\n\n\n\n\nJun 30, 2022\n\n\nKjell Jorner\n\n\n\n\n\n\n  \n\n\n\n\nAssigning chiral information with SMARTS templates\n\n\nHow to transform an achiral molecule into a chiral based on a chiral template in RDKit\n\n\n\n\n\n\nOct 15, 2021\n\n\nKjell Jorner\n\n\n\n\n\n\nNo matching items"
  }
]